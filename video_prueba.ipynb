{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\albsa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 52s - 66ms/step - accuracy: 0.9006 - loss: 0.2529 - val_accuracy: 0.9337 - val_loss: 0.1820\n",
      "Epoch 2/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9357 - loss: 0.1698 - val_accuracy: 0.9457 - val_loss: 0.1459\n",
      "Epoch 3/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9429 - loss: 0.1490 - val_accuracy: 0.9001 - val_loss: 0.5708\n",
      "Epoch 4/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9484 - loss: 0.1363 - val_accuracy: 0.9594 - val_loss: 0.1133\n",
      "Epoch 5/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9530 - loss: 0.1254 - val_accuracy: 0.9584 - val_loss: 0.1119\n",
      "Epoch 6/10\n",
      "782/782 - 48s - 61ms/step - accuracy: 0.9565 - loss: 0.1157 - val_accuracy: 0.9587 - val_loss: 0.1159\n",
      "Epoch 7/10\n",
      "782/782 - 47s - 60ms/step - accuracy: 0.9595 - loss: 0.1076 - val_accuracy: 0.9663 - val_loss: 0.0928\n",
      "Epoch 8/10\n",
      "782/782 - 47s - 60ms/step - accuracy: 0.9622 - loss: 0.1021 - val_accuracy: 0.9685 - val_loss: 0.0906\n",
      "Epoch 9/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9639 - loss: 0.1006 - val_accuracy: 0.9676 - val_loss: 0.0929\n",
      "Epoch 10/10\n",
      "782/782 - 46s - 59ms/step - accuracy: 0.9640 - loss: 0.0961 - val_accuracy: 0.9676 - val_loss: 0.0905\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "Precision: 0.8618843683083511\n",
      "Recall: 0.805\n",
      "F1-Score: 0.8324715615305068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten,  Conv2D, MaxPooling2D, BatchNormalization, Input, Add, SeparableConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir el número de clases para clasificación binaria\n",
    "NUM_CLASES = 2\n",
    "\n",
    "# Cargar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Índice de la clase \"barco\" en CIFAR-10\n",
    "indice_barco = 8  # \"ship\" es la clase con índice 8\n",
    "\n",
    "# Etiquetas: 1 para \"barco\", 0 para \"no barco\"\n",
    "y_train_bin = np.where(y_train.flatten() == indice_barco, 1, 0)\n",
    "y_test_bin = np.where(y_test.flatten() == indice_barco, 1, 0)\n",
    "\n",
    "# Normalizar los valores de los píxeles en el rango [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_bin, NUM_CLASES)\n",
    "y_test_cat = to_categorical(y_test_bin, NUM_CLASES)\n",
    "\n",
    "# Función para ajustar una imagen a 32x32\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (32, 32))\n",
    "    normalized_frame = resized_frame.astype('float32') / 255.0\n",
    "    return normalized_frame\n",
    "\n",
    "\n",
    "# Función para construir CNN avanzada utilizando la API Funcional\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Primera capa convolucional con Batch Normalization\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Segunda capa convolucional separable con Batch Normalization\n",
    "    x = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Residual block\n",
    "    residual = Conv2D(64, (1, 1), padding='same')(x)\n",
    "    res = BatchNormalization()(residual)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Add()([x, res])  # Conexión residual\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Capa de Flatten y Densa\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Construir y compilar el modelo\n",
    "model_barco = build_cnn((32, 32, 3), NUM_CLASES)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model_barco.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# (Opcional) Aumento de Datos para mejorar la generalización\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Entrenamiento del modelo con aumento de datos\n",
    "model_barco.fit(\n",
    "    datagen.flow(x_train, y_train_cat, batch_size=64),\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test_cat),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluación del modelo\n",
    "y_pred = model_barco.predict(x_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Para 'softmax'\n",
    "\n",
    "precision = precision_score(y_test_bin, y_pred_classes)\n",
    "recall = recall_score(y_test_bin, y_pred_classes)\n",
    "f1 = f1_score(y_test_bin, y_pred_classes)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "def sliding_window_detector_notebook(video_path, model, \n",
    "                                     window_size=(25, 25), step_size=2,\n",
    "                                     save_dir='detected_frames'):\n",
    "    # Crear directorio para guardar frames detectados si no existe\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_count = 0\n",
    "    detected_frame_count = 0\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        detections = []  # Guardar las coordenadas de las detecciones\n",
    "        \n",
    "        # Recorrer la imagen con ventana deslizante\n",
    "        for y in range(0, frame_height - window_size[1] + 1, step_size):\n",
    "            for x in range(0, frame_width - window_size[0] + 1, step_size):\n",
    "                window = frame[y:y + window_size[1], x:x + window_size[0]]\n",
    "                if window.shape[:2] != window_size:\n",
    "                    continue\n",
    "                \n",
    "                # Preprocesar la ventana\n",
    "                window2 = cv2.resize(window, (32, 32))\n",
    "                processed_window = window2.astype('float32') / 255.0\n",
    "                processed_window = np.expand_dims(processed_window, axis=0)  # Expandir las dimensiones\n",
    "                \n",
    "                # Predicción\n",
    "                prediction = model.predict(processed_window)\n",
    "                \n",
    "                # Asumiendo que el modelo devuelve probabilidades con softmax\n",
    "                predicted_class = prediction.argmax(axis=1)[0]\n",
    "                \n",
    "                if predicted_class == 1:\n",
    "                    # Agregar coordenadas de la detección a la lista\n",
    "                    detections.append((x, y, x + window_size[0], y + window_size[1]))\n",
    "        \n",
    "        # Dibujar las detecciones en el frame\n",
    "        for (x1, y1, x2, y2) in detections:\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Si hay al menos una detección, guarda el frame\n",
    "        if detections:\n",
    "            detected_frame_count += 1\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            save_path = os.path.join(save_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Convertir el frame a RGB para matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mostrar el frame con detecciones\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(frame_rgb)\n",
    "        plt.title(f\"Frame {frame_count} / {total_frames} - Detecciones: {len(detections)}\")\n",
    "        plt.axis('off')\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        # Limpiar la salida para mostrar un frame a la vez en el notebook\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    video.release()\n",
    "    clear_output()\n",
    "    print(f\"Proceso completado. Total de frames procesados: {frame_count}\")\n",
    "    print(f\"Total de frames con detecciones: {detected_frame_count}\")\n",
    "    print(f\"Frames detectados guardados en la carpeta: '{save_dir}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Total de frames procesados: 24\n",
      "Total de frames con detecciones: 3\n",
      "Frames detectados guardados en la carpeta: 'detected_frames'\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el detector en el video\n",
    "sliding_window_detector_notebook('barco3.mp4', model_barco)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
