{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c4e474",
   "metadata": {},
   "source": [
    "Trabajo final \n",
    "Redees Neuronales\n",
    "Flores Lara Alberto 6BV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8c1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Input, Add, SeparableConv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros\n",
    "NUM_CLASES = 10\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 1. Cargar y Preprocesar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalizar los valores de los píxeles en el rango [0, 1]\n",
    "x_train_resized = x_train.astype('float32') / 255.0\n",
    "x_test_resized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50c2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Definir Funciones para Construir Modelos\n",
    "\n",
    "# 2.1. Función para construir MLP\n",
    "def build_mlp(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.2. Función para construir CNN básica\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.3. Función para construir CNN con regularización\n",
    "def build_cnn_regularized(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.4. Función para construir CNN avanzada\n",
    "def build_cnn_advanced(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Primera capa convolucional con Batch Normalization\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Segunda capa convolucional separable\n",
    "    x = SeparableConv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Residual block\n",
    "    residual = Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Add()([x, residual])  # Conexión residual\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_layer = Dense(NUM_CLASES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# 2.5. Función para construir Transfer Learning (ResNet50))\n",
    "def build_cnn_transfer_learning(input_shape):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# 2.6. Función para construir Fine Tuning (ResNet50))\n",
    "def build_cnn_fine_tuning(input_shape):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers[:-10]:  # Desbloqueamos las últimas 10 capas\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la funcion de entrenamiento y evaluacion de los modelos\n",
    "\n",
    "# Lista para almacenar los resultados de cada modelo\n",
    "results = []\n",
    "\n",
    "def train_and_evaluate(model, model_name, x_train, y_train, x_test, y_test, epochs=EPOCHS, batch_size=BATCH_SIZE, fine_tune=False):\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Almacenar resultados\n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Exactitud': accuracy,\n",
    "        'Precisión': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Tiempo de Entrenamiento (s)': end_time - start_time\n",
    "    })\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"Exactitud: {accuracy:.4f}, Precisión: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\\n\")\n",
    "\n",
    "    return history, end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Entrenar y evaluar MLP\n",
    "print(\"Entrenando MLP...\")\n",
    "model_mlp = build_mlp((32, 32, 3))\n",
    "history_mlp, time_mlp = train_and_evaluate(model_mlp, 'MLP', x_train_resized, y_train_cat, x_test_resized, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d19dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Entrenar y evaluar CNN básica\n",
    "print(\"Entrenando CNN Básica...\")\n",
    "model_cnn = build_cnn((32, 32, 3))\n",
    "history_cnn, time_cnn = train_and_evaluate(model_cnn, 'CNN Básica', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d974a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Entrenar y evaluar CNN regularizada\n",
    "print(\"Entrenando CNN Regularizada...\")\n",
    "model_cnn_reg = build_cnn_regularized((32, 32, 3))\n",
    "history_cnn_reg, time_cnn_reg = train_and_evaluate(model_cnn_reg, 'CNN Regularizada', x_train_resized, y_train_cat, x_test_resized, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4. Entrenar y evaluar CNN avanzada\n",
    "print(\"Entrenando CNN Avanzada...\")\n",
    "model_cnn_adv = build_cnn_advanced((32, 32, 3))\n",
    "history_cnn_adv, time_cnn_adv = train_and_evaluate(model_cnn_adv, 'CNN Avanzada', x_train_resized, y_train_cat, x_test_resized, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5. Entrenar y evaluar CNN con Transfer Learning\n",
    "model_cnn_tl = build_cnn_transfer_learning((32, 32, 3))\n",
    "history_resnet50, time_resnet50 = train_and_evaluate(model_cnn_tl, 'Transfer Learning ResNet50', x_train_resized, y_train_cat, x_test_resized, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6. Entrenar y evaluar CNN con Fine Tuning\n",
    "model_cnn_ft = build_cnn_fine_tuning((32, 32, 3))\n",
    "history_resnet50, time_resnet50 = train_and_evaluate(model_cnn_ft, 'Fine Tuning ResNet50', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb793e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Gráficas de las métricas\n",
    "metrics = ['Exactitud', 'Precisión', 'Recall', 'F1-score', 'Tiempo de Entrenamiento (s)']\n",
    "num_metrics = len(metrics)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    plt.bar(df_results['Modelo'], df_results[metric], color='skyblue')\n",
    "    plt.title(metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for index, value in enumerate(df_results[metric]):\n",
    "        if metric != 'Tiempo de Entrenamiento (s)':\n",
    "            plt.text(index, value + 0.005, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "        else:\n",
    "            plt.text(index, value + 1, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de clases para clasificación binaria\n",
    "NUM_CLASES = 2\n",
    "\n",
    "# Cargar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Índice de la clase \"barco\" en CIFAR-10\n",
    "indice_barco = 8  # \"ship\" es la clase con índice 8\n",
    "\n",
    "# Etiquetas: 1 para \"barco\", 0 para \"no barco\"\n",
    "y_train_bin = np.where(y_train.flatten() == indice_barco, 1, 0)\n",
    "y_test_bin = np.where(y_test.flatten() == indice_barco, 1, 0)\n",
    "\n",
    "# Normalizar los valores de los píxeles en el rango [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_bin, NUM_CLASES)\n",
    "y_test_cat = to_categorical(y_test_bin, NUM_CLASES)\n",
    "\n",
    "# Función para ajustar una imagen a 32x32\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (32, 32))\n",
    "    normalized_frame = resized_frame.astype('float32') / 255.0\n",
    "    return normalized_frame\n",
    "\n",
    "# Construir y compilar el modelo\n",
    "model_barco = build_cnn_advanced((32, 32, 3))\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model_barco.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Aumento de Datos para mejorar la generalización\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Entrenamiento del modelo con aumento de datos\n",
    "model_barco.fit(\n",
    "    datagen.flow(x_train, y_train_cat, batch_size=64),\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test_cat),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluación del modelo\n",
    "y_pred = model_barco.predict(x_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Para 'softmax'\n",
    "\n",
    "precision = precision_score(y_test_bin, y_pred_classes)\n",
    "recall = recall_score(y_test_bin, y_pred_classes)\n",
    "f1 = f1_score(y_test_bin, y_pred_classes)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b88d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_detector_notebook(video_path, model, \n",
    "                                     window_size=(25, 25), step_size=2,\n",
    "                                     save_dir='detected_frames'):\n",
    "    # Crear directorio para guardar frames detectados si no existe\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_count = 0\n",
    "    detected_frame_count = 0\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        detections = []  # Guardar las coordenadas de las detecciones\n",
    "        \n",
    "        # Recorrer la imagen con ventana deslizante\n",
    "        for y in range(0, frame_height - window_size[1] + 1, step_size):\n",
    "            for x in range(0, frame_width - window_size[0] + 1, step_size):\n",
    "                window = frame[y:y + window_size[1], x:x + window_size[0]]\n",
    "                if window.shape[:2] != window_size:\n",
    "                    continue\n",
    "                \n",
    "                # Preprocesar la ventana\n",
    "                window2 = cv2.resize(window, (32, 32))\n",
    "                processed_window = window2.astype('float32') / 255.0\n",
    "                processed_window = np.expand_dims(processed_window, axis=0)  # Expandir las dimensiones\n",
    "                \n",
    "                # Predicción\n",
    "                prediction = model.predict(processed_window)\n",
    "                \n",
    "                # Asumiendo que el modelo devuelve probabilidades con softmax\n",
    "                predicted_class = prediction.argmax(axis=1)[0]\n",
    "                \n",
    "                if predicted_class == 1:\n",
    "                    # Agregar coordenadas de la detección a la lista\n",
    "                    detections.append((x, y, x + window_size[0], y + window_size[1]))\n",
    "        \n",
    "        # Dibujar las detecciones en el frame\n",
    "        for (x1, y1, x2, y2) in detections:\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Si hay al menos una detección, guarda el frame\n",
    "        if detections:\n",
    "            detected_frame_count += 1\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            save_path = os.path.join(save_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Convertir el frame a RGB para matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mostrar el frame con detecciones\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(frame_rgb)\n",
    "        plt.title(f\"Frame {frame_count} / {total_frames} - Detecciones: {len(detections)}\")\n",
    "        plt.axis('off')\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        # Limpiar la salida para mostrar un frame a la vez en el notebook\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    video.release()\n",
    "    clear_output()\n",
    "    print(f\"Proceso completado. Total de frames procesados: {frame_count}\")\n",
    "    print(f\"Total de frames con detecciones: {detected_frame_count}\")\n",
    "    print(f\"Frames detectados guardados en la carpeta: '{save_dir}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eea264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el detector en el video\n",
    "sliding_window_detector_notebook('barco3.mp4', model_barco)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
