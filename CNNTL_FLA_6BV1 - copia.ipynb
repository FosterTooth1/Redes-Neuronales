{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flores Lara Alberto 6BV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación para CIFAR usando CNN con Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16, vgg16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir las funciones para crear la CNN con transfer learning y para el entrenamiento y validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_resize(image):\n",
    "    # Convertir el array a una imagen PIL\n",
    "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    # Redimensionar la imagen a 224x224\n",
    "    image = image.resize((224, 224))\n",
    "    # Convertir de nuevo a array numpy\n",
    "    image = np.array(image).astype('float32')\n",
    "    # Aplicar el preprocesamiento específico de VGG16\n",
    "    image = vgg16.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "# Función para construir CNN con Transfer Learning\n",
    "def build_cnn_transfer_learning(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False  # Congelar las capas del modelo base\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Mejor que Flatten para evitar demasiados parámetros\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)  # Añadir Dropout para evitar overfitting\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, train_generator, validation_data, epochs=30, steps_per_epoch=100, validation_steps=50):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),  # Usar una tasa de aprendizaje más baja\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_data,\n",
    "        validation_steps=validation_steps\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred = np.argmax(model.predict(validation_data[0]), axis=1)\n",
    "    y_true = np.argmax(validation_data[1], axis=1)\n",
    "    report = classification_report(y_true, y_pred, target_names=[f'Clase {i}' for i in range(10)])\n",
    "    print(report)\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "    return history, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Redimensionar las imágenes a 224x224\n",
    "x_train_resized = resize_images(x_train, size=(224, 224))\n",
    "x_test_resized = resize_images(x_test, size=(224, 224))\n",
    "\n",
    "# Aplicar el preprocesamiento específico de VGG16\n",
    "x_train_preprocessed = vgg16.preprocess_input(x_train_resized)\n",
    "x_test_preprocessed = vgg16.preprocess_input(x_test_resized)\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "# Crear generadores de datos con Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(x_train_preprocessed, y_train_cat, batch_size=64)\n",
    "\n",
    "validation_datagen = ImageDataGenerator()  # Sin augmentación para validación\n",
    "validation_generator = validation_datagen.flow(x_test_preprocessed, y_test_cat, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializar el modelo con el tamaño de nuestras imagenes y realizar el entrenamiento con la validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y entrenar el modelo\n",
    "model_cnn_tl = build_cnn_transfer_learning((224, 224, 3))\n",
    "history_cnn_tl, time_cnn_tl = train_and_evaluate(\n",
    "    model_cnn_tl,\n",
    "    train_generator,\n",
    "    validation_data=(x_test_preprocessed, y_test_cat),\n",
    "    epochs=30,\n",
    "    steps_per_epoch=len(x_train_preprocessed) // 64,\n",
    "    validation_steps=len(x_test_preprocessed) // 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar precisión de entrenamiento y validación\n",
    "def plot_history(histories, labels):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for history, label in zip(histories, labels):\n",
    "        plt.plot(history.history['accuracy'], label=f'{label} - Entrenamiento', linestyle='--')\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{label} - Validación')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_history([history_cnn_tl], ['CNN Transfer Learning'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
