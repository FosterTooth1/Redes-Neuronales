{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo final \n",
    "Redees Neuronales\n",
    "Flores Lara Alberto 6BV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Input, Add, SeparableConv2D, Resizing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros\n",
    "NUM_CLASES = 10\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)  # Tamaño requerido por VGG16 y ResNet50\n",
    "\n",
    "# 1. Cargar y Preprocesar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalizar los valores de los píxeles en el rango [0, 1]\n",
    "x_train_resized = x_train.astype('float32') / 255.0\n",
    "x_test_resized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASES)\n",
    "\n",
    "# Lista para almacenar los resultados de cada modelo\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Definir Funciones para Construir Modelos\n",
    "\n",
    "# 2.1. Función para construir MLP\n",
    "def build_mlp(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.2. Función para construir CNN básica\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.3. Función para construir CNN con regularización\n",
    "def build_cnn_regularized(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.4. Función para construir CNN avanzada\n",
    "def build_cnn_advanced(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Primera capa convolucional con Batch Normalization\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Segunda capa convolucional separable\n",
    "    x = SeparableConv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Residual block\n",
    "    residual = Conv2D(64, (1, 1), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Add()([x, residual])  # Conexión residual\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_layer = Dense(NUM_CLASES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# 2.5. Función para construir Transfer Learning (ResNet50))\n",
    "def build_fine_tuning_resnet50(input_shape, num_classes):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Congelar todas las capas inicialmente\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Resizing(224, 224, input_shape=input_shape))\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 2.6. Función para construir Fine Tuning (ResNet50)\n",
    "def fine_tune_resnet50(model, base_model, x_train, y_train, x_test, y_test, epochs=10, batch_size=32):\n",
    "    # Descongelar las últimas 4 capas del modelo base\n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Compilar el modelo con una tasa de aprendizaje más baja\n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Almacenar resultados\n",
    "    results.append({\n",
    "        'Modelo': 'Fine Tuning ResNet50 (Final)',\n",
    "        'Exactitud': accuracy,\n",
    "        'Precisión': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Tiempo de Entrenamiento (s)': end_time - start_time\n",
    "    })\n",
    "\n",
    "    print(f\"Modelo: Fine Tuning ResNet50 (Final)\")\n",
    "    print(f\"Exactitud: {accuracy:.4f}, Precisión: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\\n\")\n",
    "\n",
    "    return history, end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, x_train, y_train, x_test, y_test, epochs=EPOCHS, batch_size=BATCH_SIZE, fine_tune=False):\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Almacenar resultados\n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Exactitud': accuracy,\n",
    "        'Precisión': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Tiempo de Entrenamiento (s)': end_time - start_time\n",
    "    })\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"Exactitud: {accuracy:.4f}, Precisión: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\\n\")\n",
    "\n",
    "    return history, end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Entrenar y evaluar MLP\n",
    "print(\"Entrenando MLP...\")\n",
    "model_mlp = build_mlp((32, 32, 3))  # Input_shape original\n",
    "history_mlp, time_mlp = train_and_evaluate(model_mlp, 'MLP', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "\n",
    "# 4.2. Entrenar y evaluar CNN básica\n",
    "print(\"Entrenando CNN Básica...\")\n",
    "model_cnn = build_cnn((32, 32, 3))  # Input_shape original\n",
    "history_cnn, time_cnn = train_and_evaluate(model_cnn, 'CNN Básica', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "\n",
    "# 4.3. Entrenar y evaluar CNN regularizada\n",
    "print(\"Entrenando CNN Regularizada...\")\n",
    "model_cnn_reg = build_cnn_regularized((32, 32, 3))  # Input_shape original\n",
    "history_cnn_reg, time_cnn_reg = train_and_evaluate(model_cnn_reg, 'CNN Regularizada', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "\n",
    "# 4.4. Entrenar y evaluar CNN avanzada\n",
    "print(\"Entrenando CNN Avanzada...\")\n",
    "model_cnn_adv = build_cnn_advanced((32, 32, 3))  # Input_shape original\n",
    "history_cnn_adv, time_cnn_adv = train_and_evaluate(model_cnn_adv, 'CNN Avanzada', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "# 5. Entrenar y Evaluar Modelos de Transfer Learning y Fine Tuning\n",
    "\n",
    "# 5.1. Transfer Learning con ResNet50\n",
    "print(\"Entrenando Transfer Learning con ResNet50...\")\n",
    "model_resnet50 = build_fine_tuning_resnet50((32, 32, 3), NUM_CLASES)\n",
    "history_resnet50, time_resnet50 = train_and_evaluate(model_resnet50, 'Fine Tuning ResNet50 (Inicial)', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "\n",
    "# 5.2. Fine Tuning con ResNet50 (Entrenamiento Inicial con Capas Congeladas)\n",
    "print(\"Entrenando Fine Tuning con ResNet50 (Inicial)...\")\n",
    "# Extraer el modelo base de ResNet50 para Fine Tuning\n",
    "base_model_resnet50 = model_resnet50.layers[0]\n",
    "\n",
    "# Realizar Fine Tuning (Descongelar últimas 4 capas y reentrenar)\n",
    "history_resnet50_finetune, time_resnet50_finetune = fine_tune_resnet50(\n",
    "    model_resnet50, \n",
    "    base_model_resnet50, \n",
    "    x_train_resized, \n",
    "    y_train_cat, \n",
    "    x_test_resized, \n",
    "    y_test_cat\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Gráficas de las métricas\n",
    "metrics = ['Exactitud', 'Precisión', 'Recall', 'F1-score', 'Tiempo de Entrenamiento (s)']\n",
    "num_metrics = len(metrics)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    plt.bar(df_results['Modelo'], df_results[metric], color='skyblue')\n",
    "    plt.title(metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for index, value in enumerate(df_results[metric]):\n",
    "        if metric != 'Tiempo de Entrenamiento (s)':\n",
    "            plt.text(index, value + 0.005, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "        else:\n",
    "            plt.text(index, value + 1, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
