{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica 1: Perceptron\n",
    "Redes Neuronales y Aprendizaje Profundo\n",
    "Rodrigo F. Román Godínez\n",
    "Flores Lara Alberto\n",
    "5BV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introducción\n",
    "En esta práctica de laboratorio implementaremos el modelo del Perceptrón, un concepto fundamental en el campo de las redes neuronales. Utilizaremos el Perceptrón para resolver un problema clásico de clasificación, como la simulación de una compuerta lógica (AND y OR), y exploraremos cómo aprende a través de su regla de aprendizaje.\n",
    "\n",
    "2. Objetivos\n",
    "    - Comprender la estructura y funcionamiento del Perceptrón.\n",
    "    - Implementar desde cero el Perceptrón utilizando Python.\n",
    "    - Aplicar la regla de aprendizaje del Perceptrón para resolver problemas de clasificación binaria.\n",
    "    - Evaluar cómo los parámetros (pesos, tasa de aprendizaje, épocas) afectan el proceso de aprendizaje del Perceptrón.\n",
    "\n",
    "3. Conceptos Clave\n",
    "    - Perceptrón: Modelo matemático inspirado en las neuronas biológicas, usado para resolver problemas de clasificación.\n",
    "    - Regla de Aprendizaje: La actualización de los pesos en función del error entre la predicción y el valor esperado.\n",
    "    - Compuertas Lógicas: Define qué son las compuertas lógicas y su importancia en el contexto del aprendizaje supervisado. Aquí puedes incluir las tablas de verdad de AND y OR.\n",
    "\n",
    "4. Materiales Necesarios\n",
    "    - Entorno de programación (Python, Google Colab, Jupyter Notebook).\n",
    "    - Librerías de Python: NumPy, opcionalmente Matplotlib para visualización.\n",
    "5. Instrucciones Paso a Paso\n",
    "    - Paso 1: Inicialización del Perceptrón\n",
    "    En este primer paso, vamos a inicializar los pesos y el sesgo del Perceptrón. Los pesos determinan la importancia de cada entrada en el modelo, y el sesgo ajusta el umbral en el que se activa la neurona.\n",
    "\n",
    "        * Crea un entorno de trabajo en tu editor de Python favorito (Google Colab, Jupyter Notebook, etc.).\n",
    "        * Define las entradas y las salidas para la compuerta lógica que quieres simular. Para este ejemplo, utilizaremos la compuerta AND.\n",
    "        * Inicializa los pesos y el sesgo a cero. Los pesos son un vector del mismo tamaño que las entradas. (Nota: Inicializar con ceros es una opción simple, pero en redes neuronales más complejas, se usan valores aleatorios pequeños.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Compuerta lógica AND\n",
    "X= np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "#Etiquetas de salida esperada para la compuerta AND\n",
    "y= np.array([0, 0, 0, 1])\n",
    "\n",
    "#Inicializamos los pesos a 0\n",
    "pesos= np.zeros(X.shape[1])\n",
    "    \n",
    "#Inicializamos el sesgo a 0\n",
    "sesgo= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paso 2: Definición de la Función de Activación\n",
    "El Perceptrón utiliza una función de activación escalonada para tomar decisiones. Esta función convierte la suma ponderada de las entradas en una salida binaria (0 o 1).\n",
    "\n",
    "    * Define la función de activación que devuelve 1 si la entrada ponderada es mayor o igual a 0, y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función de activación\n",
    "def activacion_escalonada(suma_ponderada):\n",
    "    return 1 if suma_ponderada >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paso 3: Algoritmo del Perceptrón\n",
    "Ahora que tenemos la función de activación, podemos implementar el algoritmo de aprendizaje del Perceptrón. El objetivo es actualizar los pesos y el sesgo de manera que el modelo aprenda a predecir correctamente las salidas esperadas.\n",
    "\n",
    "    * Define una tasa de aprendizaje. Este valor controla cuánto cambian los pesos durante el proceso de entrenamiento.\n",
    "    * Implementa el algoritmo de aprendizaje. La fórmula para actualizar los pesos y el sesgo se basa en el error entre la salida predicha y la salida esperada.\n",
    "    * Entrenamiento del modelo: El algoritmo recorre cada muestra de entrenamiento, predice la salida, y luego ajusta los pesos y el sesgo si la predicción fue incorrecta.\n",
    "    * Entrena el Perceptrón con los datos de la compuerta AND. Utiliza la función perceptron_train() (o el nombre que hayas definido) para ajustar los pesos y el sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El algoritmo realizo ajustes durante:  3  epocas\n"
     ]
    }
   ],
   "source": [
    "# Definimos la tasa de aprendizaje y el número de épocas para entrenar\n",
    "tasa_aprendizaje = 0.1\n",
    "epocas = 10\n",
    "\n",
    "def entrenar_perceptron(X,y,tasa_aprendizaje,epocas,pesos,sesgo):\n",
    "    \n",
    "    for epoca in range(epocas):\n",
    "        #Definimos un contador para detener el ciclo en caso de que no haya errores durante el entrenamiento en una epoca\n",
    "        contador= 0\n",
    "        #Iteramos sobre cada muestra de entrenamiento\n",
    "        for i in range(X.shape[0]):\n",
    "            #Calculamos la suma ponderada\n",
    "            suma_ponderada = np.dot(X[i], pesos) + sesgo\n",
    "            #Generamos la predicción utilizando la función de activación escalonada\n",
    "            prediccion = activacion_escalonada(suma_ponderada)\n",
    "            #Calculamos el error como la diferencia entre la predicción y la etiqueta esperada\n",
    "            error = y[i] - prediccion\n",
    "            \n",
    "            #Actualizamos los pesos si es necesario\n",
    "            if error != 0:\n",
    "                pesos += tasa_aprendizaje * error * X[i]\n",
    "                sesgo += tasa_aprendizaje * error\n",
    "                contador += 1\n",
    "                \n",
    "        if contador == 0:\n",
    "            break\n",
    "\n",
    "    # Retornamos los pesos y el sesgo entrenados\n",
    "    return pesos, sesgo, epoca\n",
    "\n",
    "# Entrenamiento del perceptron usando los datos del modelo AND\n",
    "pesos, sesgo, epoca = entrenar_perceptron(X, y,tasa_aprendizaje, epocas,pesos, sesgo)\n",
    "print(\"El algoritmo realizo ajustes durante: \", epoca, \" epocas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paso 4: Predicciones con el Perceptrón\n",
    "Ahora que el Perceptrón está entrenado, es hora de hacer predicciones usando los pesos y el sesgo aprendidos.\n",
    "\n",
    "    * Define una función de predicción. Esta función tomará las entradas y aplicará los pesos, el sesgo y la función de activación para predecir la salida.\n",
    "    * Prueba el modelo con los mismos datos de la compuerta AND para ver si el Perceptrón ha aprendido correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruebas del modelo AND:\n",
      "Entrada: [0 0] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [0 1] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [1 0] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [1 1] - Predicción: 1 - Esperado: 1\n"
     ]
    }
   ],
   "source": [
    "#Función para hacer las predicciones utilizando los pesos y sesgo entrenados\n",
    "def predecir(X, pesos, sesgo):\n",
    "    #Calculamos la suma ponderada de las características de entrada con los pesos\n",
    "    suma_ponderada = np.dot(X, pesos) + sesgo\n",
    "    #Devolvemos la predicción utilizando la función de activación escalonada\n",
    "    return activacion_escalonada(suma_ponderada)\n",
    "\n",
    "#Hacemos pruebas con las compuertas del modelo AND\n",
    "print(\"\\nPruebas del modelo AND:\")\n",
    "for i in range(X.shape[0]):\n",
    "    # Hacemos la predicción\n",
    "    pred = predecir(X[i], pesos, sesgo)\n",
    "    print(f\"Entrada: {X[i]} - Predicción: {pred} - Esperado: {y[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paso 5: Evaluación y Ajustes\n",
    "En esta etapa, el estudiantes debe evaluar los resultados obtenidos y experimentar con\n",
    "los parámetros del modelo.\n",
    "\n",
    "    * Modifica la tasa de aprendizaje y las épocas para ver cómo afecta al rendimiento\n",
    "    del Perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El algoritmo realizo ajustes durante:  5  epocas\n",
      "\n",
      "Pruebas del modelo AND:\n",
      "Entrada: [0 0] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [0 1] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [1 0] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [1 1] - Predicción: 1 - Esperado: 1\n"
     ]
    }
   ],
   "source": [
    "#Inicializamos los pesos a 0\n",
    "pesos= np.zeros(X.shape[1])\n",
    "    \n",
    "#Inicializamos el sesgo a 0\n",
    "sesgo= 0\n",
    "\n",
    "# Definimos la tasa de aprendizaje y el número de épocas para entrenar\n",
    "tasa_aprendizaje = 0.25\n",
    "epocas = 15\n",
    "\n",
    "# Entrenamiento del perceptron usando los datos del modelo AND con parametros modificados\n",
    "pesos, sesgo, epoca = entrenar_perceptron(X, y,tasa_aprendizaje, epocas,pesos, sesgo)\n",
    "print(\"El algoritmo realizo ajustes durante: \", epoca, \" epocas\")\n",
    "\n",
    "#Hacemos pruebas con las compuertas del modelo AND con parametros modificados\n",
    "print(\"\\nPruebas del modelo AND:\")\n",
    "for i in range(X.shape[0]):\n",
    "    # Hacemos la predicción\n",
    "    pred = predecir(X[i], pesos, sesgo)\n",
    "    print(f\"Entrada: {X[i]} - Predicción: {pred} - Esperado: {y[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paso 6: Actividad Opcional\n",
    "    * Como actividad adicional, los estudiantes pueden implementar una compuerta lógica OR\n",
    "    o intentar entrenar el Perceptrón con la compuerta XOR (sabiendo que fallará en este\n",
    "    último caso, ya que el Perceptrón no puede resolver problemas no lineales como XOR).\n",
    "\n",
    "    * También puede implementar una función para graficar los resultados del modelo y poder\n",
    "    visualizar la frontera de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El algoritmo realizo ajustes durante:  3  epocas\n",
      "\n",
      "Pruebas del modelo OR:\n",
      "Entrada: [0 0] - Predicción: 0 - Esperado: 0\n",
      "Entrada: [0 1] - Predicción: 1 - Esperado: 1\n",
      "Entrada: [1 0] - Predicción: 1 - Esperado: 1\n",
      "Entrada: [1 1] - Predicción: 1 - Esperado: 1\n"
     ]
    }
   ],
   "source": [
    "#Inicializamos los pesos a 0\n",
    "pesos= np.zeros(X.shape[1])\n",
    "    \n",
    "#Inicializamos el sesgo a 0\n",
    "sesgo= 0\n",
    "\n",
    "# Definimos la tasa de aprendizaje y el número de épocas para entrenar\n",
    "tasa_aprendizaje = 0.1\n",
    "epocas = 10\n",
    "\n",
    "# Entrenamiento del perceptron usando los datos del modelo OR\n",
    "#Etiquetas de salida esperada para la compuerta OR\n",
    "y= np.array([0, 1, 1, 1])\n",
    "\n",
    "pesos, sesgo, epoca = entrenar_perceptron(X, y,tasa_aprendizaje, epocas,pesos, sesgo)\n",
    "print(\"El algoritmo realizo ajustes durante: \", epoca, \" epocas\")\n",
    "\n",
    "#Hacemos pruebas con las compuertas del modelo AND con parametros modificados\n",
    "print(\"\\nPruebas del modelo OR:\")\n",
    "for i in range(X.shape[0]):\n",
    "    # Hacemos la predicción\n",
    "    pred = predecir(X[i], pesos, sesgo)\n",
    "    print(f\"Entrada: {X[i]} - Predicción: {pred} - Esperado: {y[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
