{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Input, Add, SeparableConv2D, Resizing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros\n",
    "NUM_CLASES = 10\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)  # Tamaño requerido por VGG16 y ResNet50\n",
    "\n",
    "# Cargar el dataset CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Definir el tamaño del subconjunto (ejemplo: 10% de los datos de entrenamiento)\n",
    "subset_size = int(0.1 * x_train.shape[0])\n",
    "\n",
    "# Seleccionar índices aleatorios para el subconjunto\n",
    "indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "\n",
    "# Crear el subconjunto\n",
    "x_train_subset = x_train[indices]\n",
    "y_train_subset = y_train[indices]\n",
    "\n",
    "# Normalizar los valores de los píxeles en el rango [0, 1]\n",
    "x_train_resized = x_train.astype('float32') / 255.0\n",
    "x_test_resized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASES)\n",
    "\n",
    "# Lista para almacenar los resultados de cada modelo\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5. Función para construir Transfer Learning (ResNet50))\n",
    "def build_cnn_transfer_learning(input_shape):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# 2.5. Función para construir Transfer Learning (ResNet50))\n",
    "def build_cnn_fine_tuning(input_shape):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers[:-10]:  # Desbloqueamos las últimas 10 capas\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output_layer = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, x_train, y_train, x_test, y_test, epochs=EPOCHS, batch_size=BATCH_SIZE, fine_tune=False):\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    accuracy = np.mean(y_pred == y_true)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Almacenar resultados\n",
    "    results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Exactitud': accuracy,\n",
    "        'Precisión': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Tiempo de Entrenamiento (s)': end_time - start_time\n",
    "    })\n",
    "\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(f\"Exactitud: {accuracy:.4f}, Precisión: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time:.2f} segundos\\n\")\n",
    "\n",
    "    return history, end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar CNN con Transfer Learning\n",
    "model_cnn_tl = build_cnn_transfer_learning((32, 32, 3))\n",
    "history_resnet50, time_resnet50 = train_and_evaluate(model_cnn_tl, 'Transfer Learning ResNet50', x_train_resized, y_train_cat, x_test_resized, y_test_cat)\n",
    "\n",
    "# Entrenar y evaluar CNN con Fine Tuning\n",
    "model_cnn_ft = build_cnn_fine_tuning((32, 32, 3))\n",
    "history_resnet50, time_resnet50 = train_and_evaluate(model_cnn_ft, 'Fine Tuning ResNet50', x_train_resized, y_train_cat, x_test_resized, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Gráficas de las métricas\n",
    "metrics = ['Exactitud', 'Precisión', 'Recall', 'F1-score', 'Tiempo de Entrenamiento (s)']\n",
    "num_metrics = len(metrics)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "    plt.bar(df_results['Modelo'], df_results[metric], color='skyblue')\n",
    "    plt.title(metric)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for index, value in enumerate(df_results[metric]):\n",
    "        if metric != 'Tiempo de Entrenamiento (s)':\n",
    "            plt.text(index, value + 0.005, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "        else:\n",
    "            plt.text(index, value + 1, f\"{value:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
